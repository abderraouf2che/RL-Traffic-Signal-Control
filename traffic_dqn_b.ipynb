{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Import Dependecies\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#PER\n",
    "from Memory import *\n",
    "\n",
    "\n",
    "# Keras and TF\n",
    "import keras.backend.tensorflow_backend as backend\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#Misc\n",
    "from collections import deque\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import os \n",
    "os.environ['CUDA_DEVICE_ORDER'] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import random \n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "#SUMO TraCI\n",
    "import traci\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Get Multiple types of states : \n",
    "\n",
    "def get_state(intersection, state_type ='n_of_vehicles', edge_length=750, max_pos=250, in_out=False,\\\n",
    "              get_reward=False, ignore_far_cars=False):\n",
    "    '''\n",
    "    Retrieve Different Types of states specified by state_type,\n",
    "    Default: n_of_vehicles. specify the horizon of detection by max_pos.\n",
    "    choose from: queue, waiting_time, throughput, queue_in_out, throughput, speed, fuel_consumption.\n",
    "    Output: Vector including lane states, and current phase state [0,1,2,3]. \n",
    "    '''\n",
    "    # retrieve incoming lanes list of the traffic light \n",
    "    lanes_list = list(traci.trafficlight.getControlledLanes(intersection))\n",
    "    # Outgoing list from the intersection\n",
    "    out_list = [lane.replace('in','out') for lane in lanes_list]\n",
    "    if in_out:\n",
    "        lanes_list+= out_list\n",
    "    N = len(lanes_list) \n",
    "    state = np.zeros((N+1 ,1), dtype=np.int32)\n",
    "    \n",
    "    # Troughput\n",
    "    if state_type == 'throughput':\n",
    "        for i,lane in enumerate(out_list): \n",
    "            veh_count = 0\n",
    "            for vehicle in traci.lane.getLastStepVehicleIDs(lane): # loop over vehicles in lane\n",
    "\n",
    "                veh_pos = traci.vehicle.getLanePosition(vehicle) # get vehicle's position\n",
    "                if veh_pos <max_pos:\n",
    "                    veh_count+=1\n",
    "            state[i] = veh_count\n",
    "      \n",
    "    #Queue In and throughput\n",
    "    elif state_type == 'queue_in_out':\n",
    "        N = len(lanes_list) + len(out_list)\n",
    "        state = np.zeros((N+1, 1), dtype=np.int32)\n",
    "        \n",
    "        for i,lane in enumerate(lanes_list):\n",
    "            \n",
    "#             lane_state = traci.lane.getLastStepHaltingNumber(lanes_list[i])\n",
    "#             state[i] = lane_state\n",
    "            veh_count=0\n",
    "            for vehicle in traci.lane.getLastStepVehicleIDs(lane):\n",
    "                veh_pos = (edge_length-17) - np.abs(int(traci.vehicle.getLanePosition(vehicle)))\n",
    "                if veh_pos <max_pos:\n",
    "                    veh_count+=1\n",
    "            state[i] = veh_count\n",
    "            \n",
    "            \n",
    "        \n",
    "        for i,lane in enumerate(out_list): \n",
    "            veh_count = 0\n",
    "            for vehicle in traci.lane.getLastStepVehicleIDs(lane):\n",
    "\n",
    "                veh_pos = traci.vehicle.getLanePosition(vehicle)\n",
    "                if veh_pos <max_pos:\n",
    "                    veh_count+=1\n",
    "            state[i+len(lanes_list)] = veh_count\n",
    "        \n",
    "        \n",
    "            \n",
    "    else:\n",
    "#         car_list = traci.vehicle.getIDList()\n",
    "        for i,lane in enumerate(lanes_list):\n",
    "            \n",
    "            # queue state\n",
    "            if state_type == 'queue':\n",
    "                lane_state = traci.lane.getLastStepHaltingNumber(lanes_list[i])#get number of Queuing/\n",
    "                                                                            #halting vehicles on lane\n",
    "                state[i] = lane_state\n",
    "           \n",
    "            \n",
    "            #waiting time state \n",
    "            elif state_type == 'waiting_time':\n",
    "                lane_state = traci.lane.getWaitingTime(lanes_list[i]) # get waiting vehicles on lane\n",
    "                \n",
    "                state[i] = lane_state\n",
    "            # Alternative waiting time state \n",
    "            elif state_type == 'waiting_time_2':\n",
    "                lane_state = 0\n",
    "\n",
    "                for car_id in traci.lane.getLastStepVehicleIDs(lane):# loop over vehicle iDs in lane\n",
    "                    wait_time = traci.vehicle.getWaitingTime(car_id) # get waiting time of the vehicle\n",
    "                    lane_id = traci.vehicle.getLaneID(car_id)  # lane id of the car\n",
    "                    if lane_id == lane:  # add waiting time of vehicles to the corresponding lane.\n",
    "                        lane_state += wait_time\n",
    "                \n",
    "                state[i] = lane_state\n",
    "            \n",
    "            \n",
    "            # Speed state\n",
    "            elif state_type == 'speed':  \n",
    "                lane_state = traci.lane.getLastStepMeanSpeed(lanes_list[i]) # Get average speed of vehicles\n",
    "                                                                            # on the given lane\n",
    "                state[i] = lane_state\n",
    "            \n",
    "            # Alternative waiting time state\n",
    "            elif state_type == 'n_of_vehicles_2':                \n",
    "                    for car_id in traci.lane.getLastStepVehicleIDs(lane):\n",
    "                        lane_id = traci.vehicle.getLaneID(car_id)\n",
    "                        if lane_id == lane:  \n",
    "                            state[i] += 1\n",
    "            # Alternative waiting time state\n",
    "            elif state_type == 'n_of_vehicles_3':\n",
    "                lane_state = traci.lane.getLastStepVehicleNumber(lanes_list[i])\n",
    "                state[i] = lane_state\n",
    "            \n",
    "            # Fuel consumption\n",
    "            elif state_type == 'fuel_consumption':\n",
    "                lane_state = traci.lane.getFuelConsumption(lanes_list[i])\n",
    "                state[i] = lane_state\n",
    "                \n",
    "            #else Number of Vehicles State. Default Choice\n",
    "            else:\n",
    "\n",
    "                lane_state = traci.lane.getLastStepVehicleNumber(lanes_list[i])\n",
    "\n",
    "                lane_approach = 0\n",
    "                veh_count = 0\n",
    "                for vehicle in traci.lane.getLastStepVehicleIDs(lane):\n",
    "\n",
    "                    if lane not in out_list:\n",
    "\n",
    "                        veh_pos = (edge_length-17) - np.abs(int(traci.vehicle.getLanePosition(vehicle)))\n",
    "                        if veh_pos<7:\n",
    "                            lane_approach=1\n",
    "\n",
    "                        if veh_pos <max_pos: #limit the horizon of detection starting from the intersection\n",
    "\n",
    "\n",
    "                            veh_count+=1\n",
    "\n",
    "#                     if lane in out_list:\n",
    "#                         veh_pos = traci.vehicle.getLanePosition(vehicle)\n",
    "#                         if veh_pos <max_pos:\n",
    "#                             veh_count+=1\n",
    "\n",
    "                if ignore_far_cars:\n",
    "                    lane_approach = lane_approach\n",
    "                else:\n",
    "                    lane_approach = 1\n",
    "\n",
    "                if lane_approach:\n",
    "                    state[i] = veh_count\n",
    "   \n",
    "    # if retrieving just the reward value, not state vector.\n",
    "    if get_reward:\n",
    "        reward = np.sum(np.array(state))\n",
    "        return reward\n",
    "    #else, we proceed with adding the state current phase to the state vector\n",
    "    else:\n",
    "        all_phases = traci.trafficlight.getAllProgramLogics(intersection) # get all phases codings from\n",
    "                                                                            #traffic light control id\n",
    "        current_phase = traci.trafficlight.getRedYellowGreenState(intersection) # get the current phase of signals\n",
    "    \n",
    "        # Encode the current phase to either 0 or 1 or 2 or 3\n",
    "        for i,phase in enumerate(all_phases[0].getPhases()):\n",
    "            s = phase.__repr__().split(',')\n",
    "            s = s[1].split('\\'')[1]\n",
    "\n",
    "            if current_phase == s:\n",
    "                state[N] = np.floor(i/2)\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#state DTSE\n",
    "\n",
    "def get_state_DTSE_2(intersection='intersection'):\n",
    "    \"\"\"\n",
    "    Retrieve DTSE of the intersection from sumo, in the form of cell occupancy\n",
    "    credits to Andrea Vidali, Wade Genders\n",
    "    \"\"\"\n",
    "    N = 80 \n",
    "    state = np.zeros(N+1)\n",
    "    car_list = traci.vehicle.getIDList()\n",
    "\n",
    "    for car_id in car_list:\n",
    "        lane_pos = traci.vehicle.getLanePosition(car_id)\n",
    "        lane_id = traci.vehicle.getLaneID(car_id)\n",
    "        lane_pos = 750 - lane_pos  # inversion of lane pos, so if the car is close to the traffic light -> lane_pos = 0 --- 750 = max len of a road\n",
    "\n",
    "        # distance in meters from the traffic light -> mapping into cells\n",
    "\n",
    "         \n",
    "        if lane_pos < 7:\n",
    "            lane_cell = 0\n",
    "        elif lane_pos < 14:\n",
    "            lane_cell = 1\n",
    "        elif lane_pos < 21:\n",
    "            lane_cell = 2\n",
    "        elif lane_pos < 28:\n",
    "            lane_cell = 3\n",
    "        elif lane_pos < 40:\n",
    "            lane_cell = 4\n",
    "        elif lane_pos < 60:\n",
    "            lane_cell = 5\n",
    "        elif lane_pos < 100:\n",
    "            lane_cell = 6\n",
    "        elif lane_pos < 160:\n",
    "            lane_cell = 7\n",
    "        elif lane_pos < 400:\n",
    "            lane_cell = 8\n",
    "        elif lane_pos <= 750:\n",
    "            lane_cell = 9\n",
    "\n",
    "        # finding the lane where the car is located \n",
    "        # x2TL_3 are the \"turn left only\" lanes\n",
    "\n",
    "        if lane_id == \"e1_in_0\" or lane_id == \"e1_in_1\" or lane_id == \"e1_in_2\":\n",
    "            lane_group = 0\n",
    "        elif lane_id == \"e1_in_3\":\n",
    "            lane_group = 1\n",
    "        elif lane_id == \"e4_in_0\" or lane_id == \"e4_in_1\" or lane_id == \"e4_in_2\":\n",
    "            lane_group = 2\n",
    "        elif lane_id == \"e4_in_3\":\n",
    "            lane_group = 3\n",
    "        elif lane_id == \"e3_in_0\" or lane_id == \"e3_in_1\" or lane_id == \"e3_in_2\":\n",
    "            lane_group = 4\n",
    "        elif lane_id == \"e3_in_3\":\n",
    "            lane_group = 5\n",
    "        elif lane_id == \"e2_in_0\" or lane_id == \"e2_in_1\" or lane_id == \"e2_in_2\":\n",
    "            lane_group = 6\n",
    "        elif lane_id == \"e2_in_3\":\n",
    "            lane_group = 7\n",
    "        else:\n",
    "            lane_group = -1\n",
    "\n",
    "        if lane_group >= 1 and lane_group <= 7:\n",
    "            car_position = int(str(lane_group) + str(lane_cell))  # composition of the two postion ID to create a number in interval 0-79\n",
    "            valid_car = True\n",
    "        elif lane_group == 0:\n",
    "            car_position = lane_cell\n",
    "            valid_car = True\n",
    "        else:\n",
    "            valid_car = False  # flag for not detecting cars crossing the intersection or driving away from it\n",
    "\n",
    "        if valid_car:\n",
    "            state[car_position] = 1  # write the position of the car car_id in the state array in the form of \"cell occupied\"\n",
    "\n",
    "            \n",
    "    all_phases = traci.trafficlight.getAllProgramLogics(intersection)\n",
    "    current_phase = traci.trafficlight.getRedYellowGreenState(intersection)\n",
    "    \n",
    "    \n",
    "    for i,phase in enumerate(all_phases[0].getPhases()):\n",
    "        s = phase.__repr__().split(',')\n",
    "        s = s[1].split('\\'')[1]\n",
    "\n",
    "        \n",
    "        if current_phase == s:\n",
    "            state[N] = np.floor(i/2)\n",
    "            \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "# Get the number of outgoing vehicles \n",
    "def get_queue_out(intersection, max_pos=250):\n",
    "    lanes_list = list(traci.trafficlight.getControlledLanes(intersection))\n",
    "    #     all_lane_list = traci.lane.getIDList()\n",
    "    out_list = [lane.replace('in','out') for lane in lanes_list]\n",
    "    queue_list = []\n",
    "\n",
    "    for lane in out_list:\n",
    "        veh_count = 0\n",
    "        for vehicle in traci.lane.getLastStepVehicleIDs(lane):\n",
    "\n",
    "            veh_pos = traci.vehicle.getLanePosition(vehicle)\n",
    "            if veh_pos < max_pos:\n",
    "                veh_count+=1\n",
    "\n",
    "        queue_list.append(veh_count)\n",
    "\n",
    "    queue = np.sum(np.asarray(queue_list))\n",
    "    return queue\n",
    "\n",
    "\n",
    "       \n",
    "# Get the total number of queuing vehicles at the intersection - Used for statistics and as a reward\n",
    "    \n",
    "def get_queue(intersection):\n",
    "    lanes_list = list(traci.trafficlight.getControlledLanes(intersection))\n",
    "    queue_list = []\n",
    "    for lane in lanes_list:\n",
    "        q = traci.lane.getLastStepHaltingNumber(lane)\n",
    "        queue_list.append(q)\n",
    "    \n",
    "    queue = np.sum(np.asarray(queue_list))\n",
    "    \n",
    "    return queue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Utils \n",
    "\n",
    "# freeze the simulation, step forward without executing new actions.\n",
    "def freeze(steps):\n",
    "    '''\n",
    "    freeze the simulation, step forward without executing new actions.\n",
    "    '''\n",
    "    #replace later by self.step_counter\n",
    "    for step in range(steps):\n",
    "        traci.simulationStep()\n",
    "        #update step counter\n",
    "        \n",
    "# choose action according to epsilon-greedy policy\n",
    "def choose_action(model, state):\n",
    "    '''\n",
    "    choose action according to epsilon-greedy policy\n",
    "    '''\n",
    "    if np.random.random < epsilon:\n",
    "        action = np.radnom.choice(action_space)\n",
    "        \n",
    "    else:\n",
    "        action = model.predict(state)\n",
    "    return action\n",
    "\n",
    "# choose a random action \n",
    "def random_action(action_size=4):\n",
    "    '''choose a random action '''\n",
    "    action_size = 4 \n",
    "    action = action = random.randrange(action_size)\n",
    "    return action\n",
    "\n",
    "# set Green phase with the specified duration for the given traffic light\n",
    "def set_green_phase(action, green_duration=15, intersection='intersection'):\n",
    "    '''\n",
    "    set Green phase with the specified duration for the given traffic light\n",
    "    '''\n",
    "    act = action\n",
    "    green_phase_code = action * 2\n",
    "    for t in range(green_duration):\n",
    "        \n",
    "        traci.trafficlight.setPhase(intersection, green_phase_code)\n",
    "        traci.simulationStep()\n",
    "    \n",
    "    \n",
    "# set Yellow phase with the specified duration for the given traffic light\n",
    "def set_yellow_phase(action, yellow_duration=3, intersection='intersection'):\n",
    "    '''\n",
    "    set Yellow phase with the specified duration for the given traffic light\n",
    "    '''\n",
    "    yellow_phase_code = action * 2 + 1\n",
    "    for t in range(yellow_duration):\n",
    "        \n",
    "        traci.trafficlight.setPhase(intersection, yellow_phase_code)\n",
    "        traci.simulationStep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Testing Performance\n",
    "\n",
    "def test_performence(agent, state_type, state_size=17, render=False, n_tests=3, time=4050, green_duration=15, episode=1,\\\n",
    "                     dist='weibull', both=False, n_cars=4000, ig_far_cars=False, verbose=1, max_pos=250 ):\n",
    "    '''\n",
    "    Test the performace of the agent with different simulation paramters\n",
    "    '''\n",
    "    # For statistics\n",
    "    average_durations = []\n",
    "    reward_lists = []\n",
    "    queue_lists = []\n",
    "    test_results = []\n",
    "    \n",
    "    #SUMO simulation configurations\n",
    "    sumoBinary = 'sumo'\n",
    "\n",
    "    options = [\"--time-to-teleport\",\"-1\",\"--statistic-output\",\"stats.xml\", \"--eager-insert\",\"True\", \\\n",
    "           \"--tripinfo-output\",\"intersection_3_info.xml\",\"--summary-output\",\"summary.xml\",\\\n",
    "           \"--tripinfo-output.write-unfinished\",\"False\"]\n",
    "    sumoCmd = [sumoBinary,\"-c\",\"intersection_3.sumocfg\",*options]\n",
    "#     episode=np.random.randint(1000)\n",
    "    \n",
    "    # Test the fixed traffic light performance for the given simulation parameters.\n",
    "    if agent=='fixed' or both:\n",
    "        generate_route_file(dist = dist, n_cars=n_cars, episode=episode) # generate flow of cars file\n",
    "        step=0\n",
    "        intersection = 'intersection' # intersection name\n",
    "        avg_durations = [] \n",
    "        queue_list = []\n",
    "        if render:\n",
    "                sumoCmd[0] = 'sumo-gui'\n",
    "        #Start the traffic simulation\n",
    "        traci.start(sumoCmd) \n",
    "        while step<time:\n",
    "\n",
    "            traci.simulationStep()\n",
    "                                    \n",
    "            queue = get_queue(intersection)                   # get sum of queues at the intersection \n",
    "            if step % (green_duration + yellow_duration) ==0: #      every a period of time\n",
    "                queue_list.append(queue)\n",
    "\n",
    "            step = step + 1\n",
    "        #Close Simulation after finishing\n",
    "        traci.close() \n",
    "        # Get Results of the simulation from the info file\n",
    "        durations = np.asarray(get_from_info(file_path='intersection_3_info.xml'), dtype=np.float32)\n",
    "        avg_durations.append(sum(durations)/len(durations))\n",
    "        print(sum(durations)/len(durations))\n",
    "        test_results.append(queue_list)\n",
    "        test_results.append(avg_durations)\n",
    "        test_results.append(durations)\n",
    "        if agent=='fixed':\n",
    "            return test_results\n",
    "    \n",
    "    # for agents\n",
    "    for n in range(n_tests):\n",
    "#         episode=np.random.randint(1000)\n",
    "        generate_route_file(dist = dist, n_cars=n_cars, episode=episode) # generate flow file\n",
    "        reward_list= []\n",
    "        queue_list = []\n",
    "        \n",
    "        if render: # render the simulation in SUMO\n",
    "            sumoCmd[0] = 'sumo-gui'\n",
    "        #Start the Simulation\n",
    "        traci.start(sumoCmd)\n",
    "        intersection = 'intersection'\n",
    "        step = 0\n",
    "        #SImulate a step\n",
    "        traci.simulationStep()\n",
    "        if verbose:\n",
    "            print('.. initialzing the simulation environment')\n",
    "            print('epsilon=',agent.epsilon)\n",
    "        # Initial state and action \n",
    "        \n",
    "        state = get_state(intersection, state_type=state_type, max_pos=max_pos)\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        old_action = agent.act(state)\n",
    "        #Select an initial the green phase \n",
    "        set_green_phase(old_action, green_duration=green_duration)\n",
    "        #assign\n",
    "        state = get_state(intersection, state_type=state_type, max_pos=max_pos)\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        \n",
    "\n",
    "        old_reward=0\n",
    "        episode_reward = 0\n",
    "        while step<time: \n",
    "\n",
    "            old_reward = np.sum(state[0][0:-1])\n",
    "    \n",
    "            action = agent.act(state) # agent's action selection according to e-greedy policy\n",
    "            if action != old_action: # if different action chosen than the previous, set yellow phase. \n",
    "                set_yellow_phase(old_action)\n",
    "\n",
    "            set_green_phase(action, green_duration=green_duration) # set the green phase \n",
    "                                                                    # according to chosen action\n",
    "            \n",
    "                \n",
    "            queue = get_queue(intersection) # get queue for stats\n",
    "            queue_list.append(queue)\n",
    "            \n",
    "            next_state = get_state(intersection, state_type=state_type, ignore_far_cars=ig_far_cars)#get the next state\n",
    "                                                                                        # after executing the action\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "            new_reward = np.sum(next_state[0][0:-1])\n",
    "            \n",
    "            reward =  - (new_reward ) # reward\n",
    "            \n",
    "            old_action = action \n",
    "            state = next_state\n",
    "\n",
    "            step = step + yellow_duration + green_duration\n",
    "\n",
    "            reward_list.append(reward)\n",
    "\n",
    "        traci.close()\n",
    "        #for every test append\n",
    "        # stats information\n",
    "        reward_lists.append(reward_list)\n",
    "        queue_lists.append(queue_list)\n",
    "        durations = np.asarray(get_from_info(file_path='intersection_3_info.xml'), dtype=np.float32)\n",
    "        average_durations.append(sum(durations)/len(durations))\n",
    "        \n",
    "        print(sum(durations)/len(durations))\n",
    "    if both:\n",
    "        return reward_lists, queue_lists, average_durations, durations, test_results\n",
    "    else:\n",
    "        return reward_lists, queue_lists, average_durations, durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Extra\n",
    "\n",
    "#Reading values for travel time list for all vehicles from the trip info generated file\n",
    "\n",
    "def get_from_info(file_path='intersection_3_info.xml',retrieve='duration'):\n",
    "    retrieve = ' '+ retrieve +'='\n",
    "\n",
    "    '''\n",
    "    Reading values for travel time list for all vehicles from the trip info generated file\n",
    "    can retrieve other information specified by the retrieve paramter, ex: waitingTime\n",
    "    '''\n",
    "    duration_list = []\n",
    "\n",
    "    with open(file_path,'r') as f:\n",
    "        text_lines = f.readlines()\n",
    "        for w in text_lines:\n",
    "            a = w.split('\"')\n",
    "            for i,value in enumerate(a):\n",
    "\n",
    "                if value==retrieve:\n",
    "                    \n",
    "                    duration_list.append(a[i+1])\n",
    "    \n",
    "    return duration_list\n",
    "\n",
    "\n",
    "def get_lanes_waiting_time(intersection):\n",
    "    '''\n",
    "    Get total waiting time of vehicles at the intersection\n",
    "    '''\n",
    "    lanes_list = list(traci.trafficlight.getControlledLanes(intersection))\n",
    "    \n",
    "    waiting_time_list = []\n",
    "    \n",
    "    for lane in lanes_list:\n",
    "        time = traci.lane.getWaitingTime(lane)\n",
    "        waiting_time_list.append(time)\n",
    "        \n",
    "    t_waiting_time = np.sum(np.asarray(waiting_time_list))\n",
    "    \n",
    "    return t_waiting_time\n",
    "    \n",
    "    \n",
    "#get current waiting time of cars  as state\n",
    "\n",
    "\n",
    "\n",
    "def get_consecutive_waiting_time(intersection='intersection'):\n",
    "    '''total current waiting time in seconds'''\n",
    "    \n",
    "    # incoming lanes list\n",
    "    lanes_list = list(traci.trafficlight.getControlledLanes(intersection)) \n",
    "    N = len(lanes_list)\n",
    "    #initialize state vector\n",
    "    state = np.zeros((N,1), dtype=np.int32)\n",
    "   \n",
    "    # get list of cars in the simulation\n",
    "    car_list = traci.vehicle.getIDList()\n",
    "    for i, lane in enumerate(lanes_list):\n",
    "        lane_state = 0\n",
    "        for car_id in car_list:\n",
    "            wait_time = traci.vehicle.getWaitingTime(car_id)\n",
    "            lane_id = traci.vehicle.getLaneID(car_id) \n",
    "            if lane_id == lane:  \n",
    "                lane_state += wait_time\n",
    "        \n",
    "        state[i] = lane_state\n",
    "    return state\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import traci\n",
    "\n",
    "# append SUMO tools to path\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "\ttools = os.path.join(os.environ['SUMO_HOME'], 'tools')\n",
    "\tsys.path.append(tools)\n",
    "else:\n",
    "\tsys.exit(\"please declare environment variable 'SUMO_HOME'\")\n",
    "\n",
    "    \n",
    "    #if the above SUMO_HOME code doesnt work, try the next with changing the location of \n",
    "    # sumo tools\n",
    "\n",
    "# try:\n",
    "#     sys.path.append(\"/PATH/TO/SUMO/TOOLS/\")\n",
    "# except:\n",
    "#     print(\"please declare environment variable 'SUMO_HOME'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Testing if simulation works (with fixed time)\n",
    "\n",
    "sumoBinary = 'sumo-gui'\n",
    "\n",
    "options = [\"--time-to-teleport\",\"-1\",\"--statistic-output\",\"stats.xml\", \"--eager-insert\",\"True\", \\\n",
    "           \"--tripinfo-output\",\"intersection_3_info.xml\",\"--summary-output\",\"summary.xml\",\\\n",
    "           \"--tripinfo-output.write-unfinished\",\"True\"]\n",
    "sumoCmd = [sumoBinary,\"-c\",\"intersection_3.sumocfg\",*options]\n",
    "\n",
    "traci.start(sumoCmd)\n",
    "intersection = 'intersection'\n",
    "step = 0\n",
    "traci.simulationStep()\n",
    "queue_list = []\n",
    "flow_list = np.zeros((16))\n",
    "while step<3800:\n",
    "\n",
    "    traci.simulationStep()\n",
    "    step = step + 33\n",
    "\n",
    "traci.close()\n",
    "\n",
    "# durations = np.asarray(get_from_info(), dtype=np.float32)\n",
    "# avg_duration = np.sum(durations)/len(durations)\n",
    "# print(avg_duration)\n",
    "# x = [i for i in range(len(durations))]\n",
    "# plt.plot(x,durations)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Plot graphs with different paramters, and save to a directory if wanted\n",
    "def plot_and_save(data, out_dir, file_name, save=True,save_data=True,\\\n",
    "                  font_size=12, font_weight='bold', x_label='Episode', y_label='y',  style='seaborn-whitegrid',\\\n",
    "                  episode=0, smoothing=True, smoothing_window=10, fig_size=(14,10), c='c', plot=True,\n",
    "                   ):\n",
    "    '''\n",
    "    Plot graphs with different paramters, and save to a directory if wanted\n",
    "    '''\n",
    "    if save_data:\n",
    "        save_score_file(data, out_dir=out_dir, file_name=file_name)\n",
    "        \n",
    "    plt.style.use(style)\n",
    "    if smoothing:\n",
    "        data = smoothing_curve(data,smoothing_window)\n",
    "    \n",
    "    font = {'family' : 'normal',\n",
    "        'weight' : font_weight,\n",
    "        'size'   : font_size}\n",
    "\n",
    "    plt.rc('font', **font)\n",
    "#     plt.rcParams.update({'font.size':14, })\n",
    "    x = [i for i in range(len(data))]\n",
    "    fig1 = plt.figure(figsize=fig_size)\n",
    "    plt.plot(x, data, c)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(file_name)\n",
    "    if save:\n",
    "        plt.savefig(out_dir + '/'+ file_name+ str(episode)+f'{episode}.png')\n",
    "    \n",
    "\n",
    "def smoothing_curve(array, window_length=10):\n",
    "    \n",
    "    '''\n",
    "    smooth using average window of length: window_length\n",
    "    '''\n",
    "    smoothened = []\n",
    "    for i in range(1,len(array)):\n",
    "        \n",
    "        x = sum(array[:i][-window_length:])/len(array[:i][-window_length:])\n",
    "        smoothened.append(x)\n",
    "    return smoothened\n",
    "    \n",
    "    \n",
    "# plot_and_save(queue_list, model_path, 'Queue', smoothing_window=10)\n",
    "\n",
    "def save_score_file(data, out_dir='scores_data', file_name='scores'):\n",
    "       \n",
    "    '''\n",
    "    Save array of scores to a file\n",
    "    '''\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "    file_path  = os.path.join(out_dir, file_name +'.txt')\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        for d in data:\n",
    "            f.write(str(d)+'\\n')\n",
    "            \n",
    "# save_score_file(a,'testing_out_scores' )\n",
    "\n",
    "def get_score_file(file_path):\n",
    "    '''\n",
    "    Get array of scores from a file path\n",
    "    '''\n",
    "    out_list = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n','')\n",
    "            n = int(float(line))\n",
    "            out_list.append(n)\n",
    "  \n",
    "    return out_list       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Generate Route File with random distribution (Normal mainly)\n",
    "\n",
    "def generate_route_file(dist = 'weibull', n_steps=3600, n_cars=4001, mu=2000, sigma=1000, episode=1, o_file=\"intersection_3.rou.xml\"):\n",
    "    r = np.random.RandomState(episode)\n",
    "    if dist=='weibull':\n",
    "        s = r.weibull(2, n_cars)\n",
    "        mins = min(s)\n",
    "        maxs = max(s)\n",
    "        \n",
    "        new_s = []\n",
    "        for v in s:\n",
    "            v = v*n_steps/(maxs-mins)\n",
    "            new_s.append(v)\n",
    "        s=new_s\n",
    "    else:\n",
    "        s = r.normal(mu, sigma, n_cars)\n",
    "    s = np.abs(np.rint(s))\n",
    "    s = sorted(s)\n",
    "\n",
    "    with open(o_file, \"w\") as routes:\n",
    "        print('<routes>', file=routes)\n",
    "        for car_id, t in enumerate(s):\n",
    "            if r.uniform()<0.75:\n",
    "                route_id = r.randint(1, 5)  \n",
    "                if route_id == 1:\n",
    "                    print(f'      <vehicle id=\"{car_id}\" depart=\"{t}\"> \\n        <route edges=\"e1_in e3_out\"/> \\n      </vehicle>',file=routes)\n",
    "                elif route_id ==2 :\n",
    "                    print(f'      <vehicle id=\"{car_id}\" depart=\"{t}\"> \\n        <route edges=\"e2_in e4_out\"/> \\n      </vehicle>',file=routes)\n",
    "                elif route_id ==3:\n",
    "                    print(f'      <vehicle id=\"{car_id}\" depart=\"{t}\"> \\n        <route edges=\"e3_in e1_out\"/> \\n      </vehicle>',file=routes)\n",
    "                elif route_id ==4:\n",
    "                    print(f'      <vehicle id=\"{car_id}\" depart=\"{t}\"> \\n        <route edges=\"e4_in e2_out\"/> \\n      </vehicle>',file=routes)\n",
    "\n",
    "            else:\n",
    "                if r.uniform()<0.5:\n",
    "                    \n",
    "                    route_id = r.randint(1, 5)  \n",
    "                    if route_id == 1:\n",
    "                        print(f'      <vehicle id=\"{car_id}\" depart=\"{t}\"> \\n        <route edges=\"e1_in e4_out\"/> \\n      </vehicle>',file=routes)\n",
    "                    elif route_id ==2 :\n",
    "                        print(f'      <vehicle id=\"{car_id}\" depart=\"{t}\"> \\n        <route edges=\"e2_in e1_out\"/> \\n      </vehicle>',file=routes)\n",
    "                    elif route_id ==3:\n",
    "                        print(f'      <vehicle id=\"{car_id}\" depart=\"{t}\"> \\n        <route edges=\"e3_in e2_out\"/> \\n      </vehicle>',file=routes)\n",
    "                    elif route_id ==4:\n",
    "                        print(f'      <vehicle id=\"{car_id}\" depart=\"{t}\"> \\n        <route edges=\"e4_in e3_out\"/> \\n      </vehicle>',file=routes)\n",
    "\n",
    "                else:\n",
    "                    route_id = r.randint(1, 5)  \n",
    "                    if route_id == 1:\n",
    "                        print(f'      <vehicle id=\"{car_id}\" depart=\"{t}\"> \\n        <route edges=\"e1_in e2_out\"/> \\n      </vehicle>',file=routes)\n",
    "                    elif route_id ==2 :\n",
    "                        print(f'      <vehicle id=\"{car_id}\" depart=\"{t}\"> \\n        <route edges=\"e2_in e3_out\"/> \\n      </vehicle>',file=routes)\n",
    "                    elif route_id ==3:\n",
    "                        print(f'      <vehicle id=\"{car_id}\" depart=\"{t}\"> \\n        <route edges=\"e3_in e4_out\"/> \\n      </vehicle>',file=routes)\n",
    "                    elif route_id ==4:\n",
    "                        print(f'      <vehicle id=\"{car_id}\" depart=\"{t}\"> \\n        <route edges=\"e4_in e1_out\"/> \\n      </vehicle>',file=routes)\n",
    "\n",
    "\n",
    "    #         else:\n",
    "\n",
    "        print('</routes>', file=routes)\n",
    "        \n",
    "        \n",
    "# Create add file for loop detectors:\n",
    "def create_induction_loops(in_or_out='out',o_file='intersection_3.add.xml'):\n",
    "    with open(o_file, \"a\") as add:\n",
    "        print('<additionals>', file=add)\n",
    "        \n",
    "        for i in range(1,5):\n",
    "            for j in range(1,5):\n",
    "                \n",
    "                print(f'<e1Detector id=\"det_e{i}_{in_or_out}_{j}\" lane=\"e{i}_{in_or_out}_{j}\" pos=\"10\" freq=\"15\" file=\"det_e{i}_{in_or_out}_{j}.out\"/>', file=add)\n",
    "\n",
    "    #         else:\n",
    "\n",
    "        print('</additionals>', file=add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#SUMO Simulation Settings\n",
    "sumoBinary = 'sumo'\n",
    "options = [\"--time-to-teleport\",\"-1\",\"--statistic-output\",\"stats.xml\", \"--eager-insert\",\"True\", \\\n",
    "           \"--tripinfo-output\",\"intersection_3_info.xml\",\"--summary-output\",\"summary.xml\",\\\n",
    "           \"--tripinfo-output.write-unfinished\",\"True\"]\n",
    "# SUMO CMD\n",
    "sumoCmd = [sumoBinary,\"-c\",\"intersection_3.sumocfg\",*options]\n",
    "\n",
    "#Some phase paramters\n",
    "\n",
    "action_space = [0,1,2,3]\n",
    "action_id = {0:'NSG',1:'EWG',2:'NSL',3:'EWL'}\n",
    "NSG = 0\n",
    "NSY = 1\n",
    "EWG = 2\n",
    "EWY = 3\n",
    "NSL = 4\n",
    "NSLY = 5\n",
    "EWL = 6\n",
    "EWLY = 7\n",
    "\n",
    "#Green and Yellow phase duration\n",
    "green_duration=15\n",
    "yellow_duration=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "action_size = 4\n",
    "state_size = 16 + action_size\n",
    "\n",
    "# DQN Agent\n",
    "class DQNAgent:\n",
    "    '''\n",
    "    Double-DQN Agent with Target Network and Prioritized Experience Replay\n",
    "    --Network Structure: Multi Layer Perceptron\n",
    "    '''\n",
    "    def __init__(self, state_size, action_size, batch_n, dropout,\\\n",
    "                 num_layers=3, hidden_neurons=128, lr=0.001, per=False):\n",
    "        \n",
    "        #Input Vector Size\n",
    "        self.state_size = state_size\n",
    "        # Number of outputs (Q-Vaules of actions (Phases))\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        #Prioritized Experience Replay Memory\n",
    "        if per:\n",
    "            self.memory = Memory(40000) #PER\n",
    "        else:\n",
    "            self.memory = deque(maxlen=40000)\n",
    "        # Discount Factor for Q-learning\n",
    "        self.gamma = 0.95\n",
    "        self.per = per\n",
    "        #Epsilon Settings\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.9750\n",
    "        self.epsilon_min = 0.02\n",
    "        # Learning rate for Network Learning\n",
    "        self.learning_rate = lr\n",
    "        \n",
    "        self.batch_n = batch_n\n",
    "        self.dropout = dropout\n",
    "        # Main Q-Network \n",
    "        self.model = self._build_model(in_size=self.state_size, act_size=self.action_size, \\\n",
    "                           num_layers=num_layers, hidden_neurons=hidden_neurons, batch_n=batch_n, dropout=dropout)\n",
    "        \n",
    "        #Traget Q-Network  \n",
    "        self.target_model = self._build_model(in_size=self.state_size, act_size=self.action_size, \\\n",
    "                           num_layers=num_layers, hidden_neurons=hidden_neurons, batch_n=batch_n, dropout=dropout)\n",
    "        self.target_model.set_weights(self.model.get_weights())      \n",
    "        self.update_couter = 0\n",
    "        \n",
    "    \n",
    "    def _build_model(self, in_size, act_size, num_layers=2, \\\n",
    "                     hidden_neurons=64, batch_n=False, dropout=False ):\n",
    "        ''' Model Builder with different paramters\n",
    "            Multi Layer Perceptron Architecture\n",
    "        '''\n",
    "        model = Sequential()\n",
    "        for layer in range(num_layers):\n",
    "            model.add(Dense(hidden_neurons, input_dim = in_size))\n",
    "            if batch_n:\n",
    "                model.add(BatchNormalization())\n",
    "            if dropout:\n",
    "                model.add(Dropout(0.2))\n",
    "            model.add(Activation(activation='relu'))\n",
    "#           \n",
    "        \n",
    "        model.add(Dense(act_size, activation='linear'))\n",
    "        #RSMProp Optimizer\n",
    "        model.compile(loss = 'mse', optimizer=RMSprop(lr=self.learning_rate) ,metrics = ['accuracy']) #Adam(lr=self.learning_rate)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#PER \n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        '''\n",
    "        Store Agent Experiences in Tuples of (state, action, reward, next_state, done)\n",
    "        \n",
    "        '''    \n",
    "        #If PER is True: Compute TD_error before storing the Experiences\n",
    "        if self.per:\n",
    "            if done:\n",
    "                target = reward\n",
    "            else:\n",
    "                \n",
    "                p_ = self.model.predict(next_state)[0]\n",
    "                pTarget_ = self.target_model.predict(next_state)[0]\n",
    "                target = reward + self.gamma*pTarget_[np.argmax(p_)]\n",
    "\n",
    "            td_error = abs(target - self.model.predict(state)[0][action])\n",
    "\n",
    "            self.memory.add(td_error, (state, action, reward, next_state, done))\n",
    "            \n",
    "        #Else if not PER, Store the Experiences immediately\n",
    "        else:\n",
    "            self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def act(self, state):\n",
    "        '''\n",
    "            epsilon-greedy action policy\n",
    "        '''\n",
    "        if np.random.rand()<self.epsilon:\n",
    "            action = random.randrange(self.action_size)\n",
    "            return action\n",
    "        \n",
    "        else:\n",
    "            act_values = self.model.predict(state)\n",
    "            action = np.argmax(act_values[0])\n",
    "            return action\n",
    "    \n",
    "    def replay(self, batch_size, update_tn_each = 5):\n",
    "        '''\n",
    "        Replay Batch of the stored Experiences and Train the Agent on them \n",
    "        '''\n",
    "        if self.per:\n",
    "            minibatch, idx, is_weight = self.memory.sample(batch_size)#PER\n",
    "        else:\n",
    "            minibatch = random.sample(self.memory, batch_size)\n",
    "            \n",
    "            \n",
    "        for i in range(batch_size):\n",
    "\n",
    "            state, action, reward, next_state, done = minibatch[i]\n",
    "            \n",
    "#         for state, action, reward, next_state in minibatch:\n",
    "            if done:\n",
    "                target = reward\n",
    "            else:\n",
    "\n",
    "                max_action = np.argmax(self.model.predict(next_state))\n",
    "                target = (reward + self.gamma*self.target_model.predict(next_state)[0][max_action])\n",
    "            \n",
    "#             target = (reward + self.gamma*np.amax(self.target_model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            \n",
    "            if self.per:\n",
    "                \n",
    "                self.model.fit(state, target_f, epochs=1, verbose = 0, sample_weight=np.array([is_weight[i]])) #PER\n",
    "            else:\n",
    "                self.model.fit(state, target_f, epochs=1, verbose = 0)\n",
    "            \n",
    "        self.update_couter+=1\n",
    "        \n",
    "        if self.update_couter % update_tn_each == 0:\n",
    "            self.update_target()\n",
    "    \n",
    "    def update_target(self):\n",
    "        self.target_model.set_weights(self.model.get_weights()) \n",
    "        \n",
    "        \n",
    "    def update_epsilon(self):\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "        \n",
    "    def save(self, name):\n",
    "        self.model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create agent instance:\n",
    "\n",
    "action_size = 4\n",
    "state_size = 16 + 1\n",
    "agent = DQNAgent(state_size=state_size, action_size=4, hidden_neurons=64, num_layers=3, dropout=False,lr=0.001, batch_n=False, per=True)\n",
    "agent.model.summary()\n",
    "agent.epsilon = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_dir = 'tls_model/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "test_dir =  os.path.join(output_dir,'test_results')\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training \n",
    "###\n",
    "batch_size = 32\n",
    "AGGREGATE_STATS_EVERY = 50 \n",
    "###\n",
    "green_durations = [15]#, 15, 20 , 30]\n",
    "flows_list = ['weibull']#,'normal']\n",
    "n_cars_list = [4001]#, 4001]#, ]#, 9600]\n",
    "state_list = ['n_of_vehicles']#,'queue', 'n_of_vehicles']\n",
    "penalty_list = [False, 'ep_reward', 'teleport']\n",
    "max_pos = 150\n",
    "n_of_experiments = 1\n",
    "n_episodes  = 501\n",
    "####\n",
    "for experiment in range(n_of_experiments):\n",
    "    for flow_type in flows_list:\n",
    "        \n",
    "        #Initialize agent\n",
    "        agent = DQNAgent(state_size=state_size, action_size=4, hidden_neurons=64,\\\n",
    "                         num_layers=3, dropout=False,lr=0.001, batch_n=False, per=True)\n",
    "        agent.epsilon = 1.\n",
    "        \n",
    "        #agent Params\n",
    "        agent.epsilon_decay =0.9914\n",
    "        \n",
    "#       Initialization\n",
    "\n",
    "        reward_list = []\n",
    "        queue_list  = []\n",
    "        travel_time_list = []\n",
    "        waiting_time_list = []\n",
    "        \n",
    "        AGGREGATE_REWARD_EVERY = 50\n",
    "        start_learning = False\n",
    "        save_label = time.ctime()\n",
    "        final_time = 3800\n",
    "        model_path = os.path.join(output_dir, save_label)\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            os.makedirs(model_path)\n",
    "            \n",
    "        #sumo cmd simulation settings\n",
    "        \n",
    "        sumoBinary = 'sumo'\n",
    "        options = [\"--time-to-teleport\",\"-1\",\"--statistic-output\",\"stats.xml\", \"--eager-insert\",\"True\", \\\n",
    "           \"--tripinfo-output\",\"intersection_3_info.xml\",\"--summary-output\",\"summary.xml\",\\\n",
    "           \"--tripinfo-output.write-unfinished\",\"False\"]\n",
    "        sumoCmd = [sumoBinary,\"-c\",\"intersection_3.sumocfg\",*options]\n",
    "\n",
    "        #random_selection of flow type\n",
    "#         flow_n = np.random.choice(range(len(flows_list))) \n",
    "#         flow_type = flows_list[flow_n]\n",
    "        #random_selection of number of cars\n",
    "        n_cars_n = np.random.choice(range(len(n_cars_list)))\n",
    "        n_cars = n_cars_list[n_cars_n]\n",
    "\n",
    "        #random_selection of number of green duration\n",
    "        green_dur_n = np.random.choice(range(len(green_durations)))\n",
    "        green_duration = green_durations[green_dur_n]\n",
    "\n",
    "        #random_selection of state_type\n",
    "        state_n = np.random.choice(range(len(state_list)))\n",
    "        state_type = state_list[state_n]\n",
    "#         state_type = 'queue'\n",
    "        #random_selection of number of state_type\n",
    "        penalty_n = np.random.choice(range(len(penalty_list)))\n",
    "        penalty_type = penalty_list[penalty_n]\n",
    "        \n",
    "        penalty_type = penalty_list[experiment]             ###\n",
    "        if penalty_type =='teleport':\n",
    "            del sumoCmd[3:5]\n",
    "\n",
    "        #fix penalty and green duration at moment\n",
    "#         penalty_type = False\n",
    "        if n_cars == 1500:\n",
    "            green_duration = 15\n",
    "        elif n_cars == 4000:\n",
    "            green_duration = 15\n",
    "        else:\n",
    "            green_duration = 15\n",
    "\n",
    "        #Penlaty threshold:\n",
    "        if state_type == 'n_of_vehicles':\n",
    "            penalty_thresh = -20000\n",
    "        elif state_type == 'queue':\n",
    "            penalty_thresh = -15000\n",
    "        else:\n",
    "            penalty_thresh = -300000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print('-------------- Setup Training with the Next Parameters --------------')\n",
    "        print('Flow Type:                    |', flow_type)\n",
    "        print('Number of cars generated:     |', n_cars)\n",
    "        print('Green Phase duration:         |', green_duration)\n",
    "        print('State and Reward Definition:  |', state_type)\n",
    "        print('Penalty Type:                 |', penalty_type)\n",
    "        print('Penalty THresh:               |', penalty_thresh)\n",
    "\n",
    "\n",
    "\n",
    "        print('--------------                                        ---------------')\n",
    "        for j,episode in enumerate(range(n_episodes)):\n",
    "\n",
    "            generate_route_file(dist = flow_type, n_cars=n_cars, episode=episode) \n",
    "            episode_reward = 0\n",
    "\n",
    "            traci.start(sumoCmd)\n",
    "            intersection = 'intersection'\n",
    "\n",
    "            traci.simulationStep()\n",
    "            step = 0\n",
    "            old_action = random_action()\n",
    "\n",
    "\n",
    "            set_green_phase(old_action, green_duration=green_duration)\n",
    "            #assign:\n",
    "\n",
    "            state = get_state(intersection, max_pos=max_pos, state_type=state_type, ignore_far_cars=False)\n",
    "            state = np.reshape(state, [1, state_size])\n",
    "\n",
    "            counter = 0\n",
    "            reward_track = deque(maxlen=5)\n",
    "            ep_queue_list = []\n",
    "            done = False\n",
    "            teleported_number = 0\n",
    "            while step<=final_time:\n",
    "\n",
    "\n",
    "\n",
    "                old_reward = np.sum(state[0][0:-1])\n",
    "                action = agent.act(state)\n",
    "\n",
    "\n",
    "                if action != old_action:\n",
    "                    set_yellow_phase(old_action)\n",
    "\n",
    "                set_green_phase(action, green_duration=green_duration)\n",
    "                step = step + yellow_duration + green_duration\n",
    "\n",
    "\n",
    "                queue = get_queue(intersection)\n",
    "\n",
    "                next_state = get_state(intersection, state_type=state_type, max_pos=max_pos, ignore_far_cars=False)\n",
    "                next_state = np.reshape(next_state, [1, state_size])\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "                new_reward = np.sum(next_state[0][0:-1])\n",
    "\n",
    "                reward = - new_reward\n",
    "                episode_reward += reward\n",
    "                ep_queue_list.append(queue)\n",
    "\n",
    "\n",
    "                next_step = step + yellow_duration + green_duration\n",
    "\n",
    "                if next_step >= final_time:\n",
    "                    done = True\n",
    "                if done:\n",
    "                    agent.remember(state, action, reward, next_state, done)\n",
    "                    break\n",
    "\n",
    "\n",
    "                reward_track.append((state, action, reward, next_state, done))\n",
    "\n",
    "                if penalty_type == 'teleport':\n",
    "\n",
    "                    teleports = traci.simulation.getStartingTeleportNumber()\n",
    "                    teleported_number += teleports\n",
    "\n",
    "                    if teleports>0:\n",
    "                        print('t:',teleported_number,'step:',step)\n",
    "                        reward = penalty_thresh / 10\n",
    "                        done = True\n",
    "                        agent.remember(state, action, reward, next_state, done)\n",
    "                        for i,tup in enumerate(reward_track):\n",
    "                            agent.remember(tup[0], tup[1], -i*(reward/10)+reward ,tup[3], tup[4])\n",
    "\n",
    "\n",
    "                        break\n",
    "\n",
    "                elif penalty_type == 'ep_reward':\n",
    "                    if episode_reward< penalty_thresh:\n",
    "                        reward = penalty_thresh/8\n",
    "                        done = True\n",
    "                        agent.remember(state, action, reward, next_state, done)\n",
    "                        for i,tup in enumerate(reward_track):\n",
    "                            agent.remember(tup[0], tup[1], -i*(reward/10)+reward ,tup[3], tup[4])\n",
    "\n",
    "                        print(step)\n",
    "                        break\n",
    "\n",
    "\n",
    "                agent.remember(state, action, reward, next_state, done)\n",
    "                reward_track.append((state, action, reward, next_state, done))\n",
    "\n",
    "                old_action = action\n",
    "                state = next_state\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #for each episode\n",
    "            \n",
    "\n",
    "            if episode>4:\n",
    "                start_learning = True\n",
    "                for _ in range(3):\n",
    "                    agent.replay(batch_size)\n",
    "                agent.update_epsilon()\n",
    "                \n",
    "    \n",
    "            reward_list.append(episode_reward)\n",
    "            queue_list.append(sum(ep_queue_list)/len(ep_queue_list))\n",
    "\n",
    "            average_reward = sum(reward_list[-AGGREGATE_REWARD_EVERY:])/len(reward_list[-AGGREGATE_REWARD_EVERY:])\n",
    "\n",
    "            average_queue = sum(queue_list[-AGGREGATE_REWARD_EVERY:])/len(queue_list[-AGGREGATE_REWARD_EVERY:])\n",
    "\n",
    "            try:\n",
    "                durations = np.asarray(get_from_info(file_path='intersection_3_info.xml'), dtype=np.float32)\n",
    "                average_travel_time = np.sum(durations)/len(durations)\n",
    "                travel_time_list.append(average_travel_time)\n",
    "                \n",
    "                waiting_times = np.asarray(get_from_info(file_path='intersection_3_info.xml',\\\n",
    "                                                         retrieve='waitingTime'), dtype=np.float32)\n",
    "                avg_waiting = np.sum(waiting_times)/len(waiting_times)  \n",
    "                print('avg waiting time: ',avg_waiting)\n",
    "                waiting_time_list.append(avg_waiting)\n",
    "                \n",
    "            except:\n",
    "                print('travel time skipped')\n",
    "\n",
    "            max_reward = max(reward_list[-AGGREGATE_REWARD_EVERY:])\n",
    "            min_reward = min(reward_list[-AGGREGATE_REWARD_EVERY:])\n",
    "\n",
    "            #Save and plot\n",
    "            if episode % AGGREGATE_REWARD_EVERY == 0 and episode!=0:\n",
    "                agent.save(model_path +'/'+'tnet'+'state_in_out'+ '{:04d}'.format(episode) + '.hdf5')\n",
    "                if episode+1 == n_episodes:\n",
    "                    file_to_store = open(model_path +'/'+'agent'+ '{:04d}'.format(episode) + '.pickle', \"wb\")\n",
    "                    pickle.dump(agent, file_to_store)\n",
    "                    file_to_store.close()\n",
    "\n",
    "                plot_and_save(reward_list, model_path, 'reward', episode=episode)\n",
    "\n",
    "\n",
    "                plot_and_save(queue_list, model_path, 'queue', episode=episode)\n",
    "\n",
    "\n",
    "                plot_and_save(travel_time_list, model_path, 'avg_travel_time', episode=episode)\n",
    "                \n",
    "                plot_and_save(waiting_time_list, model_path, 'avg_waiting_time', episode=episode)\n",
    "\n",
    "    #         print('episode : {}/{}, episode_reward {}, avg_queu {}, e={:.2}'.format(episode, n_episodes, episode_reward, average_queue, agent.epsilon))\n",
    "\n",
    "            try:\n",
    "                \n",
    "                durations = np.asarray(get_from_info(), dtype=np.float32)\n",
    "                avg_duration = np.sum(durations)/len(durations)    \n",
    "                print('episode :{}/{}, episode_reward {}, avg_queu {}, e={:.2}, avg_time:{}'.format(episode, n_episodes, episode_reward, \\\n",
    "                                                                                                    average_queue, agent.epsilon,avg_duration))\n",
    "            except:\n",
    "                print('info file error')\n",
    "\n",
    "            traci.close()\n",
    "\n",
    "        average_travel_time = sum(travel_time_list[-AGGREGATE_REWARD_EVERY:])\\\n",
    "        /len(travel_time_list[-AGGREGATE_REWARD_EVERY:])\n",
    "        print('avg travel time:{}'.format(average_travel_time))\n",
    "        \n",
    "        # Testing Performance\n",
    "\n",
    "        rs, qs, avg_dur, durations = test_performence(agent=agent, state_type=state_type, n_cars=n_cars,\\\n",
    "                                                  render=False, n_tests=15,time=3800, max_pos=250,\\\n",
    "                                                  both=False, ig_far_cars=False, verbose=0, green_duration=green_duration)    \n",
    "\n",
    "        print('mean avg travel time:{}'.format(np.mean(avg_dur)))\n",
    "        # Plotting test results\n",
    "        plot_and_save(rs[-1], model_path, 'test_reward', save=True, smoothing=True, smoothing_window=10)\n",
    "        plot_and_save(qs[-1], model_path, 'test_queue', save=True, smoothing=True, smoothing_window=10)\n",
    "        plot_and_save(durations, model_path, 'test_travel_time', save=True, smoothing=True, smoothing_window=10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Example if loading a saved agent --> uncomment\n",
    "\n",
    "# from keras.models import load_model\n",
    "# agent = DQNAgent(state_size=state_size, action_size=4, hidden_neurons=64, num_layers=3, dropout=False,lr=0.001, batch_n=False, per=True)\n",
    "# model_path = 'tls_model/weibull_4000_15_n_veh_150__No_penalty/'\n",
    "# agent.model   = load_model(model_path+ 'tnetstate_in_out0500.hdf5')\n",
    "# agent.epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "state_type = 'n_of_vehicles'\n",
    "green_duration =15\n",
    "flow_type = 'weibull'\n",
    "n_cars = 4001\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Test fixed and Actuated agents\n",
    "\n",
    "# results = test_performence(agent='fixed', state_type=state_type, n_cars=n_cars,\\\n",
    "#                                           render=False, n_tests=1,time=3800, max_pos=250, dist=flow_type,\\\n",
    "#                                           both=False, ig_far_cars=False, verbose=0, green_duration=green_duration)   \n",
    "\n",
    "# print('mean avg travel time:{}'.format(np.mean(results[2])))\n",
    "# # Plotting test results\n",
    "# plot_and_save(results[2], model_path, 'test_reward_', save=False, smoothing=True, smoothing_window=10)\n",
    "# plot_and_save(results[0], model_path, 'test_queue_', save=False, smoothing=True, smoothing_window=10)\n",
    "# plot_and_save(durations, model_path, 'test_travel_time', save=False, smoothing=True, smoothing_window=10)\n",
    "\n",
    "rs, qs, avg_dur, durations = test_performence(agent=agent, state_type=state_type, state_size=state_size,\\\n",
    "                                              n_cars=n_cars, episode=11,\\\n",
    "                                          render=False, n_tests=2,time=3800, max_pos=150, dist=flow_type,\\\n",
    "                                          both=False, ig_far_cars=False, verbose=0, green_duration=green_duration)   \n",
    "\n",
    "# print('mean avg travel time:{}'.format(np.mean(avg_dur)))\n",
    "# Plotting test results\n",
    "plot_and_save(rs[-1], model_path, 'test_reward_2', save=True, smoothing=True, smoothing_window=10)\n",
    "plot_and_save(qs[-1], model_path, 'test_queue_2', save=True, smoothing=True, smoothing_window=10)\n",
    "plot_and_save(durations, model_path, 'test_travel_time_2', save=True, smoothing=True, smoothing_window=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testing the agent on random episodes\n",
    "\n",
    "state_type = 'n_of_vehicles'\n",
    "green_duration =15\n",
    "flow_type = 'weibull'\n",
    "n_cars = 4001\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Random episodes\n",
    "rand_eps = [ 70, 950, 495, 823, 113, 148, 732, 876, 518, 517]\n",
    "res = {}\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,1):\n",
    "    print('->>>>>>>', agent_type)\n",
    "    agent = DQNAgent(state_size=state_size, action_size=4, hidden_neurons=64, num_layers=3, dropout=False,lr=0.001, batch_n=False, per=True)\n",
    "    agent.epsilon = 0\n",
    "    agent.model   = load_model('tls_model/'+'selected/'+ agent_type+ '/tnetstate_in_out0500.hdf5')\n",
    "    avgerage_time = []\n",
    "    for i in rand_eps:\n",
    "\n",
    "        rs, qs, avg_dur, durations = test_performence(agent=agent, state_type=state_type, state_size=state_size,\\\n",
    "                                                      n_cars=n_cars, episode=i,\\\n",
    "                                              render=False, n_tests=1, time=3800, max_pos=150, dist=flow_type,\\\n",
    "                                              both=False, ig_far_cars=False, verbose=0, green_duration=green_duration)\n",
    "        avgerage_time.append(avg_dur)\n",
    "    res[agent_type] = avgerage_time\n",
    "    print('mean avg travel time:{}'.format(np.mean(avgerage_time)))\n",
    "\n",
    "#     Plotting test results\n",
    "plot_and_save(rs[-1], model_path, 'test_reward', save=False, smoothing=True, smoothing_window=10)\n",
    "plot_and_save(qs[-1], model_path, 'test_queue', save=False, smoothing=True, smoothing_window=10)\n",
    "plot_and_save(durations, model_path, 'test_travel_time', save=False, smoothing=True, smoothing_window=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "state_size = 17\n",
    "flow_type = 'weibull'\n",
    "state_type = 'queue'\n",
    "n_cars = 4001\n",
    "agent = DQNAgent(state_size=state_size, action_size=4, hidden_neurons=64, num_layers=3, dropout=False,lr=0.001, batch_n=False, per=True)\n",
    "model_path = 'tls_model/selected/q_s_-_q_reward_penalty_143_penalty__no-ignoring'\n",
    "agent.model   = load_model(model_path+ '/tnetstate_in_out0400.hdf5')\n",
    "agent.epsilon = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rs, qs, avg_dur, durations = test_performence(agent=agent, state_type=state_type, state_size=state_size,\\\n",
    "                                              n_cars=n_cars, episode=11,\\\n",
    "                                          render=False, n_tests=1,time=3800, max_pos=150, dist=flow_type,\\\n",
    "                                          both=False, ig_far_cars=False, verbose=0, green_duration=green_duration)   \n",
    "\n",
    "# print('mean avg travel time:{}'.format(np.mean(avg_dur)))\n",
    "# Plotting test results\n",
    "plot_and_save(rs[-1], model_path, 'test_reward', save=True, smoothing=True, smoothing_window=10)\n",
    "plot_and_save(qs[-1], model_path, 'test_queue', save=True, smoothing=True, smoothing_window=10)\n",
    "plot_and_save(durations, model_path, 'test_travel_time', save=True, smoothing=True, smoothing_window=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
